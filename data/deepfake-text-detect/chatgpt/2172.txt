This is purely from anecdotal, self researched and experiential knowledge, so feel free to correct me if there are any glaring issues in my position. I believe that some of these problems may be related or even caused by the fact that many developers don't "work" on their software as much once it has been released into production - at least not until things start breaking. In a world where we have more than enough time for feature creep during development (during which bugs can easily be discovered), but very little after release due to our ever-growing backlogs, surely this would lead us down a path where features get added just because they can without providing real value? We know what users want: A working implementation with all promised functionality delivered! In turn, we could stop looking back at code long since shipped as legacy technology (which will inevitably cause headaches later) and look forward towards improving implementations right now instead; focusing only on getting work done today rather than trying to make something perfect before moving onto other tasks tomorrow. This way you reduce future maintenance costs too and create better products quicker. Furthermore, fixing actual quality complaints reduces your support ticket volume while keeping customers happy... who doesn't like doing that?! So why aren't people pursuing this approach when building and maintaining systemssoftware? Just think about how many times the term 'legacy' gets thrown around here within the context of software engineering... its pretty common to see new projects being built atop old ones thus inheriting those specific pieces of tech rather then using them as a starting point to design an entirely new system. I'm definitely guilty myself of falling into particular traps such as not caring anymore whether components actually integrate well together or behave fairly consistently etc., simply because the application needs to ship sooner and I need to keep up morale amongst team members etc.. The pressure often comes from management asking about progress for yet another task whilst knowing full well that major blockers exist preventing certain deliverables. Being quite senior sometimes means taking responsibility for making difficult decisions regarding resources, but also understanding priorities, tradeoffs and deadlines for delivery. Sometimes though especially with teams lacking in experience, everyone feels pressured (and understandably!) about delivering results quickly regardless of technical feasibility or business impact. Addressing current customer demands isn't always feasible either given resource constraints or perhaps limited budgets. Finally let's consider how security threats evolve over time whereas solutions frequently stay static. If anything static, our efforts should go toward automating everything possible and having solid internal controls already setup beforehand to ensure best practices are adhered to. All these factors combine to push engineers away from thinking critically about architecture and relying solely upon past experiences to guide decisionmaking based off assumptions made previously. It seems that most devs prefer dealing with immediate concerns first and foremost. Its easy to forget good programming habits along the way and fall victim to bad coding practices leading to broken applications. Maybe thats part of life really...but shouldn't automated testing help alleviate some of that pain via flagging potential flaws early? Testing should never end nor take precedence above other aspects of project execution IMHO.