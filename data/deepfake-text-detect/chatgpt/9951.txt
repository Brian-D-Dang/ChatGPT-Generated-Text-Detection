Edit: I didn't expect this to get such a response. I've replied to some things and gave out some deltas, but as I won't have time to address everything, I'll have to leave the rest up to you all. To answer some of the questions: 1) Yes, I'm using a 4-layer perceptron with sigmoid activation functions in the hidden layers and linear activation in the output layer. 2) I'm using backpropagation to update the weights of the network, although I do have some regularization to prevent overfitting. 3) The dataset is fairly small (around 1000 samples), but it is balanced and has no missing values. 4) I've tried different learning rates and batch sizes, but haven't seen much improvement. I will try adjusting these parameters more and see what happens. 5) As for the data pre-processing, I'm normalizing the inputs and outputs, as well as one-hot encoding the categorical features.