I am an American High School student who was taught 2 different versions of the Civil war throughout my schooling career. In elementary school we first learned about the civil war from a very neutral perspective, almost as if both sides were just fighting to fight and had no real reason behind it all other than "it's what they did back then." It wasn't until middle school where I began learning that slavery played a huge part in the conflict, which is only true for one side (the South). The conflict before this time frame focused on states rights rather than slavery since there weren't any slaves yet at the time when many people still thought African Americans would be fully integrated into society within their lifetime. The version of history I have been taught has always seemed pretty biased towards me being white but I don't really agree with how most black students are treated like second class citizens because of something thousands of years ago. Then again maybe it could also help them realize we are not so different after all... What do you think? What can we learn by teaching our children about racism today? Should schools teach American History from beginning to end or should each subject matter get its own lesson? How much of your education has been affected by race issues?