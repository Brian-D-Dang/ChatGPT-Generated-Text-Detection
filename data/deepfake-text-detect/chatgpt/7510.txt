There are several reasons why this statement might not necessarily hold true. Firstly, the rapid advancements in technology have made it difficult to predict the extent of its capabilities in the future. As AI and other super technologies get smarter and more complex, the risk of them becoming uncontrollable and posing a threat to humanity increases. Secondly, it is essential to consider the possibility of human error in programming such technologies. Even the most advanced algorithms and codes run the risk of bugs that could lead to unintended consequences or harmful outcomes. Lastly, there is the possibility that super technologies could be used maliciously by human beings, intentionally or unintentionally causing widespread harm. Ethically challenged individuals could use AI to achieve goals that are harmful to society or to create destructive autonomous weapons systems. Therefore, it is not wise to dismiss entirely the idea that the world could end due to AI or super technology. Instead, it is better to monitor and regulate the development of these technologies to avoid potential negative consequences.