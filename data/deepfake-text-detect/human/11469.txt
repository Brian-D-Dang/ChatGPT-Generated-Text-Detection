GPT-3 is OpenAI's new language model. It has 175 billion parameters, but it is unclear whether a full version or whether one of seven smaller versions will be released. GPT-3 is an autoregressive model trained with unsupervised machine learning. It can generate news articles, use novel words in sentences, and perform arithmetic. The model achieved nearly state-of-the-art results in COPA and ReCoRD reading comprehension data sets but fell short in some sets of middle school and high school exam questions that required comparing two sentences or snippets. An analysis of the model found that it had some biases, likely due to the input data.