Complex models are commonly used in predictive modeling. In this paper we present R packages that can be used for explaining predictions from complex black box models and attributing parts of these predictions to input features. We introduce two new approaches and corresponding packages for such attribution, namely pkg live and pkg breakDown. We also compare their results with existing implementations of state-of-the-art solutions, namely pkg lime that implements Locally Interpretable Model-agnostic Explanations and pkg ShapleyR that implements Shapley values.