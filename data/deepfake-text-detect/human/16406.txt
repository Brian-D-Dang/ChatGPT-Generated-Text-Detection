Consider the estimation of a signal x R N from noisy observations r x z, where the input x is generated by an independent and identically distributed (i.i.d.) Gaussian mixture source, and z is additive white Gaussian noise (AWGN) in parallel Gaussian channels. Typically, the l 2 -norm error (squared error) is used to quantify the performance of the estimation process. In contrast, we consider the l -norm error (worst case error). For this error metric, we prove that, in an asymptotic setting where the signal dimension - N , the l -norm error always comes from the Gaussian component that has the largest variance, and the Wiener filter asymptotically achieves the optimal expected l -norm error. The i.i.d. Gaussian mixture case is easily applicable to i.i.d. Bernoulli-Gaussian distributions, which are often used to model sparse signals. Finally, our results can be extended to linear mixing systems with i.i.d. Gaussian mixture inputs, in settings where a linear mixing system can be decoupled to parallel Gaussian channels.