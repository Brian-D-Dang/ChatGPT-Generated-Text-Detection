Feminists believe women are the same as men, except for some slight biological differences in the genitals. They don't merely want equal rights for women, they also want women to be treated the same as men socially and culturally. I think this is bogus. Feminism grew big between the 60s and the 80s, when people strongly believed in the malleability of society and [nurture] was chosen above nature. This is false. Modern research has shown that personality and behavior are far more dependent on biology (brain, genes) than previously understood. There are significant differences (in general) between male and female brains. [In the past] , all males had to act masculine and females had to act feminine. Instead of ending gender stereotypes, [feminists have created a new unisex stereotype] : letting females behave more like males and letting males behave a bit more feminine. Both options are wrong and harmful. [In reality] , many males seem to be predisposed toward masculine behavior (for example aggressiveness and competitiveness), and the same holds true for females and feminine behavior. On average, boys just have more testosterone in their bodies. Not all of them are aggressive, and there are aggressive females too, but if you're looking at big groups, there is a significant difference. So if there are more male boxers, criminals, politicians and businessmen than females, that might just be biology, and not 'the patriarchy'. The idea that women are exactly the same as men seems to be harmful. Women should be fully equal in political and legal rights, but it's not 'wrong' if a certain group (a job or a community) has more males than females, or vice versa. Some governments try to 'correct' this with quotas, and I think that's harmful. I don't think we should strive for a unisex world - I think we should learn to accept feminine males, masculine females, feminine females and masculine males.