I believe that, at the end of the day, America (and to a lesser extent, the UK and USSR) ultimately lost the second World War in every way that matters. I am not disputing the fact that the United States achieved its principal militarypolitical goals (defeat of the Third Reich and the Japanese Empire), and I of course recognize the fact that the US managed to do so with virtually no civilian casualties destruction of the homeland, which is especially impressive given the sheer scale of civilian destruction seen in World War II. What I am arguing is that, having'won' (as much as it is possible to win) the war, the United States promptly lost its soul, and has ended up in a worse position than Germany or Japan. The reason (I claim) that this is true is because, even before the last Germans had surrendered and the war in Europe ended, the Cold War had already begun. The United States quickly exchanged one enemy (Nazi Germany) for another enemy (The Soviet Union). From 1945 to 1990-ish, combating the Soviet Union and the spread of communism was perhaps the centerpiece of American foreign policy, and led the United States into a variety of fights where we otherwise had no business (such as Vietnam), and ultimately begat a lot of hatred for the United States, leading to many of the foreign policy difficulties America now faces (particularly anti-US terrorism). The Truman Doctrine and containment strategy eventually gave way to a neoconservative'Pax Americana' ideal, that the United States is some kind of global police force tasked with maintaining order. I think it is clear from Iraq that US military presence generally does not breed goodwill, and therefore the United States (in trying to maintain global power) has led itself into something of a downward spiral. In trying to eliminate one enemy (for example, Iran), we adopt what may seem like a reasonable strategy (arming their enemies, the Iraqis), which eventually backfires and requires later invention (the Gulf War and Iraq war), which itself leads to further issues (like the emergence of ISIS), and on and on and on. It's a cycle that only leads to cartoonishly large military budgets and American blood spilled in conflicts where we don't belong. In short, hegemony has not been kind to the United States, and we would be better off if we weren't a world power. Contrast this with the Japanese and Germans, who are (arguably) doing rather well for themselves. Sure, each country was broken and defeated at the end of the war, and it took a very long time for them to recover, but they came out better. I say they came out better because neither the Japanese nor Germany have the'obligation' to police the world. In fact, both countries forbid themselves from taking offensive military action. While these countries can be (and often are) considered'western', and are sometimes the target of anti-western hate, they are not widely hated like the United States, and are not tasked with maintaining ridiculous global military presence. Rather (and forgive me for oversimplifying), Germany can focus on Germany and Japan can focus on Japan. One need not look long to find a wealth of statistics to indicate that these two nations have far superior social safety nets, education, healthcare, etc. than the United States. While this superiority can, of course, be attributed to a wide variety of factors, I believe that one cannot ignore the important fact that these nations have their priorities straight, having suffered the shame of defeat, having gone through the experience of rebuilding and being free of any expectation of global military prowess. What really solidifies this belief for me is the existence of universal health care in most of western Europe. I apologize that I don't have the source, but if I remember correctly, I remember watching an interview with a worker in the UK's NHS, who attributed the success of socialized medicine in Europe (versus the US) to the fact that Europe had to rebuild after World War II. Effectively, when you have to start from scratch and pick your life up from the rubble, there's a greater sense of common bond with the rest of your nation. The US, having not been hurt in the war in the same way, never had to rebuild and instead developed a more violently individualistic character, where the idea of potentially paying for someone else's health care is utterly repulsive. Americans, by virtue of having won World War II without civilian casualty, has ended up with a far worse society than those who'lost'. If that's the case, aren't we the real losers? Sorry if this post got long. Please, CMV! Hello, users of CMV! This is a footnote from your moderators. We'd just like to remind you of a couple of things. Firstly, please remember to [read through our rules] . If you see a comment that has broken one, it is more effective to report it than downvote it. Speaking of which, [downvotes don't change views] ! If you are thinking about submitting a CMV yourself, please have a look through our [popular topics wiki] first. Any questions or concerns? Feel free to [message us] . Happy CMVing!