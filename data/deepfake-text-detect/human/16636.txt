We study detection of random signals corrupted by noise that over time switchtheir values (states) from a finite set of possible values, where theswitchings occur at unknown points in time. We model such signals by means of arandom duration model that to each possible state assigns a probability massfunction which controls the statistics of durations of that state occurrences.Assuming two possible signal states and Gaussian noise, we derive optimallikelihood ratio test and show that it has a computationally tractable form ofa matrix product, with the number of matrices involved in the product being thenumber of process observations. Each matrix involved in the product is ofdimension equal to the sum of durations spreads of the two states, and it canbe decomposed as a product of a diagonal random matrix controlled by theprocess observations and a sparse constant matrix which governs transitions inthe sequence of states. Using this result, we show that the Neyman-Pearsonerror exponent is equal to the top Lyapunov exponent for the correspondingrandom matrices. Using theory of large deviations, we derive a lower bound onthe error exponent. Finally, we show that this bound is tight by means ofnumerical simulations.